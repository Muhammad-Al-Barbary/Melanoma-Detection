{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 55, 55, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,509,633\n",
      "Trainable params: 41,506,881\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Al-Barbary\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow import keras\n",
    "import keras.layers as layers\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=96, kernel_size=(11, 11), \n",
    "                        strides=(4, 4), activation=\"relu\", \n",
    "                        input_shape=(227, 227, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(5, 5), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.optimizers.SGD(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "dataset=[]\n",
    "for dirname, _, filenames in os.walk('C:/Users/Muhammad Al-Barbary/OneDrive/Desktop/Education/One-Lab Intern/Melanoma Detection/PH2Dataset/PH2 Dataset images'):\n",
    "    for filename in filenames:\n",
    "        image = Image.open(os.path.join(dirname, filename))\n",
    "        image=image.resize((227, 227))\n",
    "        image= np.asarray(image)\n",
    "        if (len(image.shape) == 3):\n",
    "            dataset.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/Muhammad Al-Barbary/OneDrive/Desktop/Education/One-Lab Intern/Melanoma Detection/PH2Dataset/PH2_dataset.csv')[12:]\n",
    "labels=[]\n",
    "for i in range(0,200):\n",
    "    if (np.asarray(df)[i][4]=='X'):\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "labels=np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.asarray(dataset)\n",
    "labels=np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size = 0.20, random_state = 0)\n",
    "X_valid, X_verif, y_valid, y_verif = train_test_split(X_test, y_test, test_size = 0.50, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.8663 - accuracy: 0.7250\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.4467 - accuracy: 0.8188\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.6890 - accuracy: 0.7625\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.5295 - accuracy: 0.8062\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.5725 - accuracy: 0.8000\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5508 - accuracy: 0.8188\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3936 - accuracy: 0.8500\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2914 - accuracy: 0.8938\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2354 - accuracy: 0.9187\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.1951 - accuracy: 0.9250\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.2631 - accuracy: 0.8875\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2460 - accuracy: 0.9312\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1118 - accuracy: 0.9625\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.1619 - accuracy: 0.9438\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.1559 - accuracy: 0.9375\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.1400 - accuracy: 0.9625\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.1181 - accuracy: 0.9563\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.1003 - accuracy: 0.9438\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0559 - accuracy: 0.9812\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0634 - accuracy: 0.9875\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0422 - accuracy: 0.9875\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.0369 - accuracy: 0.9937\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0210 - accuracy: 0.9937\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0421 - accuracy: 0.9812\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0494 - accuracy: 0.9812\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0343 - accuracy: 0.9875\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0383 - accuracy: 0.9937\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0306 - accuracy: 0.9875\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 12s 3s/step - loss: 0.0256 - accuracy: 0.9937\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0327 - accuracy: 0.9937\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0282 - accuracy: 0.9937\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0274 - accuracy: 0.9937\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0316 - accuracy: 0.9875\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.0312 - accuracy: 0.9875\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0227 - accuracy: 0.9937\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0295 - accuracy: 0.9875\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.0130 - accuracy: 0.9937\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.0161 - accuracy: 0.9937\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0195 - accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24850fe0be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 618ms/step\n"
     ]
    }
   ],
   "source": [
    "# for i in range(160):\n",
    "#     print(y_valid[i])\n",
    "#     new_image = tf.expand_dims(X_valid[i],0)\n",
    "#     prediction=model.predict(new_image);\n",
    "#     print(prediction,\"       \")\n",
    "prediction_train= np.around(model.predict(X_train)).reshape(160).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 505ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_valid= np.around(model.predict(X_valid)).reshape(20).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train=0\n",
    "for i in range(len(prediction_train)):\n",
    "    if y_train[i]== prediction_train[i]:\n",
    "        accuracy_train+=1\n",
    "accuracy_train=accuracy_train/len(prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_valid=0\n",
    "for i in range(len(prediction_valid)):\n",
    "    if y_valid[i]== int(round(prediction_valid[i])):\n",
    "        accuracy_valid+=1\n",
    "accuracy_valid=accuracy_valid/len(prediction_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training set is 0.9625\n",
      "accuracy of validation set is 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy of training set is {accuracy_train}\")\n",
    "print(f\"accuracy of validation set is {accuracy_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 326ms/step\n",
      "1 0\n",
      "accuracy of verification set is 0.95\n"
     ]
    }
   ],
   "source": [
    "prediction_verif= np.around(model.predict(X_verif)).reshape(20).astype(int)\n",
    "accuracy_verif=0\n",
    "for i in range(len(prediction_verif)):\n",
    "    if y_verif[i]== prediction_verif[i]:\n",
    "        accuracy_verif+=1\n",
    "accuracy_verif=accuracy_verif/len(prediction_verif)\n",
    "print(f\"accuracy of verification set is {accuracy_verif}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ef2af15255169531a06c842966204fd31cb89956011d167f4fe0d908cc67114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
